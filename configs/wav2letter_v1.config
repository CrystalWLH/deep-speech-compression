[GENERAL]
model_type = teacher
save_model = /home/users/sgarda/cache/tensorboard-logdir/w2l_v1
input_channels = 39
data_format = channels_last
conv_type = conv

[FILES]
vocab_path = /home/users/sgarda/project/tfrecord_data/ctc_vocab.pkl
train_data = /home/users/sgarda/project/tfrecord_data/tfrecords_mfccs.train
eval_data = /home/users/sgarda/project/tfrecord_data/tfrecords_mfccs.dev-clean
test_data = /home/users/sgarda/project/tfrecord_data/tfrecords_mfccs.test-clean

[TRAIN]
batch_size = 64
epochs = 20
activation = elu
bn = false
clipping = 0
adam_lr = 1e-4
adam_eps = 1e-8

[LM]
lm = True
beam_search = True
knlem_op = ./lm_op/libctc_decoder_with_kenlm.so
lm_binary = ./lm_data/lm.binary
lm_trie = ./lm_data/trie
lm_alphabet = ./lm_data/alphabet.txt
lm_weight = 1.75
word_count_weight = 1.00
valid_word_count_weight = 1.00
top_paths = 1
beam_width = 1024

[TEACHER]
filters = [250,250, 250, 250, 250, 250, 250, 250, 2000, 2000]
widths = [ 48,7, 7, 7, 7, 7, 7, 7, 32, 1]
strides = [2,1, 1, 1, 1, 1, 1, 1, 1, 1]
dropouts = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]





